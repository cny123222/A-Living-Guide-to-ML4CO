{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ab97d4b",
   "metadata": {},
   "source": [
    "# Fancy but Useful Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68cc7613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d73a45",
   "metadata": {},
   "source": [
    "## 增减维度：squeeze & unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8828a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([1, 2, 3]) torch.Size([3])\n",
      "\n",
      "Add a new dimension at position 0:\n",
      "tensor([[1, 2, 3]]) torch.Size([1, 3])\n",
      "\n",
      "Add a new dimension at position 1:\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]]) torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "x0 = torch.tensor([1, 2, 3])\n",
    "print(\"Original tensor:\")\n",
    "print(x0, x0.shape)\n",
    "\n",
    "# Add a new dimension at position 0\n",
    "x1 = x0.unsqueeze(0)\n",
    "print(\"\\nAdd a new dimension at position 0:\")\n",
    "print(x1, x1.shape)\n",
    "\n",
    "# Add a new dimension at position 1\n",
    "x2 = x0.unsqueeze(1)\n",
    "print(\"\\nAdd a new dimension at position 1:\")\n",
    "print(x2, x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4c39317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape: torch.Size([1, 3, 1, 5])\n",
      "\n",
      "Shape after removing all dimensions of size 1: torch.Size([3, 5])\n",
      "\n",
      "Shape after removing dim=0: torch.Size([3, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "y0 = torch.rand(1, 3, 1, 5)\n",
    "print(\"Original tensor shape:\", y0.shape)\n",
    "\n",
    "# Remove all dimensions of size 1\n",
    "y1 = y0.squeeze()\n",
    "print(\"\\nShape after removing all dimensions of size 1:\", y1.shape)\n",
    "\n",
    "# Remove dimension at position 0\n",
    "y2 = y0.squeeze(0)\n",
    "print(\"\\nShape after removing dim=0:\", y2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce60290",
   "metadata": {},
   "source": [
    "## 合并张量：cat & stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee16f92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensors:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) torch.Size([2, 3])\n",
      "tensor([[ 7,  8,  9],\n",
      "        [10, 11, 12]]) torch.Size([2, 3])\n",
      "\n",
      "Concatenated on dim=0:\n",
      "tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 11, 12]]) torch.Size([4, 3])\n",
      "\n",
      "Concatenated on dim=1:\n",
      "tensor([[ 1,  2,  3,  7,  8,  9],\n",
      "        [ 4,  5,  6, 10, 11, 12]]) torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[1, 2, 3],\n",
    "                   [4, 5, 6]])\n",
    "t2 = torch.tensor([[7, 8, 9],\n",
    "                   [10, 11, 12]])\n",
    "print(\"Original tensors:\")\n",
    "print(t1, t1.shape)\n",
    "print(t2, t2.shape)\n",
    "\n",
    "# Concatenate t1 and t2 along dimension 0\n",
    "t3 = torch.cat((t1, t2), dim=0)\n",
    "print(\"\\nConcatenated on dim=0:\")\n",
    "print(t3, t3.shape)\n",
    "\n",
    "# Concatenate t1 and t2 along dimension 1\n",
    "t4 = torch.cat((t1, t2), dim=1)\n",
    "print(\"\\nConcatenated on dim=1:\")\n",
    "print(t4, t4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94fd639a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensors:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]]) torch.Size([3, 3])\n",
      "tensor([[10, 11, 12],\n",
      "        [13, 14, 15],\n",
      "        [16, 17, 18]]) torch.Size([3, 3])\n",
      "\n",
      "Stacked on dim=0:\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6],\n",
      "         [ 7,  8,  9]],\n",
      "\n",
      "        [[10, 11, 12],\n",
      "         [13, 14, 15],\n",
      "         [16, 17, 18]]]) torch.Size([2, 3, 3])\n",
      "\n",
      "Stacked on dim=1:\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [10, 11, 12]],\n",
      "\n",
      "        [[ 4,  5,  6],\n",
      "         [13, 14, 15]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [16, 17, 18]]]) torch.Size([3, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "t2 = torch.tensor([[10, 11, 12],\n",
    "                   [13, 14, 15],\n",
    "                   [16, 17, 18]])\n",
    "print(\"Original tensors:\")\n",
    "print(t1, t1.shape)\n",
    "print(t2, t2.shape)\n",
    "\n",
    "# Stack t1 and t2 along dimension 0\n",
    "t3 = torch.stack((t1, t2), dim=0)\n",
    "print(\"\\nStacked on dim=0:\")\n",
    "print(t3, t3.shape)\n",
    "\n",
    "# Stack t1 and t2 along dimension 1\n",
    "t4 = torch.stack((t1, t2), dim=1)\n",
    "print(\"\\nStacked on dim=1:\")\n",
    "print(t4, t4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4b2803",
   "metadata": {},
   "source": [
    "## 扩展张量：expand & repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02392aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]]) torch.Size([3, 1])\n",
      "\n",
      "Expanded tensor:\n",
      "tensor([[1, 1, 1, 1],\n",
      "        [2, 2, 2, 2],\n",
      "        [3, 3, 3, 3]]) torch.Size([3, 4])\n",
      "\n",
      "Expanded tensor after modifying original tensor:\n",
      "tensor([[100, 100, 100, 100],\n",
      "        [  2,   2,   2,   2],\n",
      "        [  3,   3,   3,   3]]) torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "x0 = torch.tensor([[1], [2], [3]]) # shape: (3, 1)\n",
    "print(\"Original tensor:\")\n",
    "print(x0, x0.shape)\n",
    "\n",
    "# Expand the dimension of size 1 to size 4.\n",
    "x1 = x0.expand(3, 4)\n",
    "print(\"\\nExpanded tensor:\")\n",
    "print(x1, x1.shape)\n",
    "\n",
    "# Modify an element in the original tensor\n",
    "x0[0][0] = 100\n",
    "print(\"\\nExpanded tensor after modifying original tensor:\")\n",
    "print(x1, x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20753f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]]) torch.Size([3, 1])\n",
      "\n",
      "Repeated tensor:\n",
      "tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3]]) torch.Size([3, 3])\n",
      "\n",
      "Repeated tensor after modifying original tensor:\n",
      "tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3]]) torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "x0 = torch.tensor([[1], [2], [3]]) # shape: (3, 1)\n",
    "print(\"Original tensor:\")\n",
    "print(x0, x0.shape)\n",
    "\n",
    "# Repeat the tensor 3 times along dimension 1\n",
    "x1 = x0.repeat(1, 3)\n",
    "print(\"\\nRepeated tensor:\")\n",
    "print(x1, x1.shape)\n",
    "\n",
    "# Modify an element in the original tensor\n",
    "x0[0][0] = 100\n",
    "print(\"\\nRepeated tensor after modifying original tensor:\")\n",
    "print(x1, x1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8785bd0",
   "metadata": {},
   "source": [
    "## 高级索引：gather & scatter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19e0e224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-Values:\n",
      "tensor([[0.1000, 0.5000, 0.2000, 0.2000],\n",
      "        [0.8000, 0.1000, 0.0500, 0.0500]]) torch.Size([2, 4])\n",
      "Actions:\n",
      "tensor([[1],\n",
      "        [0]]) torch.Size([2, 1])\n",
      "\n",
      "Gathered Q-Values:\n",
      "tensor([[0.5000],\n",
      "        [0.8000]]) torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "# Assume batch_size=2, num_actions=4\n",
    "# Each row represents a state, and each column represents the Q-value for an action.\n",
    "q_values = torch.tensor([[0.1, 0.5, 0.2, 0.2],  # Q-values for state 1\n",
    "                         [0.8, 0.1, 0.05, 0.05]]) # Q-values for state 2\n",
    "\n",
    "# Assume these are the actions we actually took for each state\n",
    "# (action 1 for the first state, action 0 for the second state).\n",
    "# Note the shape is (2, 1) to match the dimensions needed for gather.\n",
    "actions = torch.tensor([[1], [0]])\n",
    "\n",
    "# dim=1 means we are indexing along the action dimension.\n",
    "# index==actions tells gather which column to pick for each row.\n",
    "# For row 0, it will pick the element at index 1 (which is 0.5).\n",
    "# For row 1, it will pick the element at index 0 (which is 0.8).\n",
    "selected_q_values = torch.gather(q_values, dim=1, index=actions)\n",
    "\n",
    "print(\"Q-Values:\")\n",
    "print(q_values, q_values.shape)\n",
    "print(\"Actions:\")\n",
    "print(actions, actions.shape)\n",
    "print(\"\\nGathered Q-Values:\")\n",
    "print(selected_q_values, selected_q_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1add67e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "tensor([[1],\n",
      "        [4],\n",
      "        [2],\n",
      "        [0]]) torch.Size([4, 1])\n",
      "\n",
      "One-Hot Encoding:\n",
      "tensor([[0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.]]) torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "# Assume batch_size=4, num_classes=5\n",
    "# Class labels\n",
    "labels = torch.tensor([1, 4, 2, 0])\n",
    "\n",
    "# 1. Create a base tensor of zeros with shape (batch_size, num_classes)\n",
    "one_hot = torch.zeros(4, 5)\n",
    "\n",
    "# 2. Prepare the index and src arguments\n",
    "# The index tensor needs to have the same number of dimensions as the\n",
    "# one_hot tensor, so we use unsqueeze to add a dimension.\n",
    "# labels.unsqueeze(1) gives it the shape (4, 1).\n",
    "labels = labels.unsqueeze(1)\n",
    "value = 1.0 # The value we want to fill in\n",
    "\n",
    "# 3. Use scatter_ to perform the one-hot encoding\n",
    "# dim=1 means we will be scattering values along the columns,\n",
    "# at the positions specified by 'index'.\n",
    "one_hot.scatter_(dim=1, index=labels, value=value)\n",
    "\n",
    "print(\"Labels:\")\n",
    "print(labels, labels.shape)\n",
    "print(\"\\nOne-Hot Encoding:\")\n",
    "print(one_hot, one_hot.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4co_cny",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
