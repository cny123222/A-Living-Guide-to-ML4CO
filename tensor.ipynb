{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "413c88b1",
   "metadata": {},
   "source": [
    "# Fancy but Useful Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "911d1d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "assert torch.cuda.is_available(), \"CUDA is not available\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6559b45",
   "metadata": {},
   "source": [
    "## 基础语法\n",
    "\n",
    "### 创建操作\n",
    "\n",
    "#### 和 NumPy 数组的转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e4e66ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original PyTorch tensor: tensor([1, 2, 3])\n",
      "Tensor after modifying NumPy array: tensor([10,  2,  3])\n"
     ]
    }
   ],
   "source": [
    "# 使用 `torch.from_numpy()` (共享内存)\n",
    "a_array = np.array([1, 2, 3])\n",
    "a_tensor = torch.from_numpy(a_array)\n",
    "print(\"Original PyTorch tensor:\", a_tensor)\n",
    "a_array[0] = 10  # 修改 NumPy 数组\n",
    "print(\"Tensor after modifying NumPy array:\", a_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0ea33a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original PyTorch tensor:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "Tensor after modifying NumPy array:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# 使用 `torch.tensor()` (复制内存)\n",
    "b_array = np.array([[1, 2], [3, 4]])\n",
    "b_tensor = torch.tensor(b_array)\n",
    "print(\"Original PyTorch tensor:\")\n",
    "print(b_tensor)\n",
    "b_array[0, 0] = 10  # 修改 NumPy 数组\n",
    "print(\"Tensor after modifying NumPy array:\")\n",
    "print(b_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "325acf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n",
      "NumPy array from CPU tensor: [1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# 从 Tensor 转换为 NumPy 数组\n",
    "c_tensor = torch.tensor([1, 2, 3], device='cuda')  # 创建一个在 GPU 上的 Tensor\n",
    "try: # GPU 上的 Tensor 不能直接转换为 NumPy 数组\n",
    "    c_array = c_tensor.numpy()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "c_array = c_tensor.cpu().numpy()\n",
    "print(\"NumPy array from CPU tensor:\", c_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dc9550",
   "metadata": {},
   "source": [
    "#### 特殊 Tensor 构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d2387ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor a:\n",
      "tensor([[0.0300, 0.8429, 0.9991],\n",
      "        [0.9456, 0.4415, 0.2493]])\n",
      "\n",
      "Tensor b with same shape as a:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2, 3)\n",
    "print(\"Random tensor a:\")\n",
    "print(a)\n",
    "\n",
    "b = torch.zeros_like(a)\n",
    "print(\"\\nTensor b with same shape as a:\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "236ebf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor a: tensor([1, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(1, 6, 2)\n",
    "print(\"Tensor a:\", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b10bc42",
   "metadata": {},
   "source": [
    "### 基本属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0eb4b5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of a: 3\n",
      "Shape of a: torch.Size([2, 3, 4])\n",
      "Shape of dim 1: 3\n",
      "Datatype of a: torch.float32\n",
      "Device of a: cuda:0\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(2, 3, 4, device='cuda')\n",
    "print(\"Rank of a:\", a.dim())\n",
    "print(\"Shape of a:\", a.shape)\n",
    "print(\"Shape of dim 1:\", a.shape[1])\n",
    "print(\"Datatype of a:\", a.dtype)\n",
    "print(\"Device of a:\", a.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438aa85a",
   "metadata": {},
   "source": [
    "### 数据类型及设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ceb98d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0.dtype: torch.float16\n",
      "x0.device: cpu\n",
      "x1.dtype: torch.float32\n",
      "x2.dtype: torch.int64\n",
      "x3.dtype: torch.int32\n",
      "x4.device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "x0 = torch.zeros(2, 3, dtype=torch.float16, device='cpu')\n",
    "print(\"x0.dtype:\", x0.dtype)\n",
    "print(\"x0.device:\", x0.device)\n",
    "x1 = x0.float()\n",
    "print(\"x1.dtype:\", x1.dtype)\n",
    "x2 = x0.long()\n",
    "print(\"x2.dtype:\", x2.dtype)\n",
    "x3 = x0.to(torch.int32)\n",
    "print(\"x3.dtype:\", x3.dtype)\n",
    "x4 = x0.to(\"cuda\")\n",
    "print(\"x4.device:\", x4.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08537fa",
   "metadata": {},
   "source": [
    "## 索引操作\n",
    "\n",
    "### 单元素索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb962ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a[0, 1]: tensor(2)\n",
      "a[0, 1].item(): 2\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"a[0, 1]:\", a[0, 1])\n",
    "print(\"a[0, 1].item():\", a[0, 1].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5168dd4",
   "metadata": {},
   "source": [
    "### 切片索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bc5bb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a[2:5]  tensor([12, 13, 14])\n",
      "a[:-1]  tensor([10, 11, 12, 13, 14, 15])\n",
      "a[::2]  tensor([10, 12, 14, 16])\n",
      "a[:]  tensor([10, 11, 12, 13, 14, 15, 16])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([10, 11, 12, 13, 14, 15, 16])\n",
    "print(\"a[2:5] \", a[2:5])  # Elements between index 2 and 5\n",
    "print(\"a[:-1] \", a[:-1])  # All elements except the last one\n",
    "print(\"a[::2] \", a[::2])  # Every second element\n",
    "print(\"a[:] \", a[:])      # All elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cef19765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single row:\n",
      "tensor([5, 6, 7, 8]) torch.Size([4])\n",
      "tensor([[5, 6, 7, 8]]) torch.Size([1, 4])\n",
      "\n",
      "Single column:\n",
      "tensor([ 3,  7, 11]) torch.Size([3])\n",
      "tensor([[ 3],\n",
      "        [ 7],\n",
      "        [11]]) torch.Size([3, 1])\n",
      "\n",
      "All columns except the last one:\n",
      "tensor([[ 1,  2,  3],\n",
      "        [ 5,  6,  7],\n",
      "        [ 9, 10, 11]]) torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "b = torch.tensor(\n",
    "    [[1, 2, 3, 4],\n",
    "     [5, 6, 7, 8],\n",
    "     [9, 10, 11, 12]]\n",
    ")\n",
    "# Single row\n",
    "print(\"Single row:\")\n",
    "print(b[1, :], b[1, :].shape)  # Equivalent to b[1]\n",
    "print(b[1:2, :], b[1:2, :].shape)\n",
    "# Single column\n",
    "print(\"\\nSingle column:\")\n",
    "print(b[:, 2], b[:, 2].shape)\n",
    "print(b[:, 2:3], b[:, 2:3].shape)\n",
    "# All columns except the last one\n",
    "print(\"\\nAll columns except the last one:\")\n",
    "print(b[:, :-1], b[:, :-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0fd9a6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 2, 3],\n",
      "        [1, 1, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "c = torch.zeros(2, 4, dtype=torch.int64)\n",
    "c[:, :2] = 1\n",
    "c[:, 2:] = torch.tensor([[2, 3], [4, 5]])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0ff886",
   "metadata": {},
   "source": [
    "### 整数 Tensor 索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "465f6bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor a:\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "\n",
      "Reordered rows:\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 0,  1,  2,  3],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 4,  5,  6,  7]])\n",
      "\n",
      "Reordered columns:\n",
      "tensor([[ 3,  2,  1,  0],\n",
      "        [ 7,  6,  5,  4],\n",
      "        [11, 10,  9,  8]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(12).reshape(3, 4)\n",
    "print(\"Original tensor a:\")\n",
    "print(a)\n",
    "\n",
    "idx = torch.tensor([0, 0, 2, 1, 1])\n",
    "print('\\nReordered rows:')\n",
    "print(a[idx])\n",
    "\n",
    "idx = torch.tensor([3, 2, 1, 0])\n",
    "print('\\nReordered columns:')\n",
    "print(a[:, idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7fdcb886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor b:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "\n",
      "Get the diagonal:\n",
      "tensor([1, 5, 9])\n",
      "\n",
      "Set the diagonal to 0:\n",
      "tensor([[0, 2, 3],\n",
      "        [4, 0, 6],\n",
      "        [7, 8, 0]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.arange(1, 10).reshape(3, 3)\n",
    "print(\"Original tensor b:\")\n",
    "print(b)\n",
    "\n",
    "idx = torch.tensor([0, 1, 2])\n",
    "print('\\nGet the diagonal:')\n",
    "print(b[idx, idx])\n",
    "\n",
    "print('\\nSet the diagonal to 0:')\n",
    "b[idx, idx] = 0\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "564a7eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor c:\n",
      "tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 11, 12]])\n",
      "\n",
      "Get elements using index arrays:\n",
      "tensor([ 2,  6,  8, 10])\n"
     ]
    }
   ],
   "source": [
    "c = torch.arange(1, 13).reshape(4, 3)\n",
    "print(\"Original tensor c:\")\n",
    "print(c)\n",
    "\n",
    "idx0 = torch.arange(c.shape[0])\n",
    "idx1 = torch.tensor([1, 2, 1, 0])\n",
    "print('\\nGet elements using index arrays:')\n",
    "print(c[idx0, idx1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a65afd",
   "metadata": {},
   "source": [
    "### 布尔 Tensor 索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c646a6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[0.6538, 0.2226, 0.1103, 0.4002],\n",
      "        [0.5974, 0.4484, 0.4929, 0.8108],\n",
      "        [0.1182, 0.5830, 0.1535, 0.8626]])\n",
      "\n",
      "Mask tensor:\n",
      "tensor([[ True, False, False, False],\n",
      "        [ True, False, False,  True],\n",
      "        [False,  True, False,  True]])\n",
      "\n",
      "Selecting elements with the mask:\n",
      "tensor([0.6538, 0.5974, 0.8108, 0.5830, 0.8626])\n",
      "\n",
      "After modifying with a mask:\n",
      "tensor([[0.0000, 0.2226, 0.1103, 0.4002],\n",
      "        [0.0000, 0.4484, 0.4929, 0.0000],\n",
      "        [0.1182, 0.0000, 0.1535, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(3, 4)\n",
    "print(\"Original tensor:\")\n",
    "print(a)\n",
    "\n",
    "mask = (a > 0.5)\n",
    "print(\"\\nMask tensor:\")\n",
    "print(mask)\n",
    "\n",
    "print('\\nSelecting elements with the mask:')\n",
    "print(a[mask])\n",
    "\n",
    "a[mask] = 0\n",
    "print('\\nAfter modifying with a mask:')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160693ec",
   "metadata": {},
   "source": [
    "## 变形操作\n",
    "\n",
    "### 改变逻辑形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e517b68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n",
      "shape: torch.Size([2, 4])\n",
      "\n",
      "Flattened tensor:\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "shape: torch.Size([8])\n",
      "\n",
      "Column vector:\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8]])\n",
      "shape: torch.Size([8, 1])\n",
      "\n",
      "Rank 3 tensor:\n",
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n",
      "shape: torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "x0 = torch.arange(1, 9).reshape(2, 4)\n",
    "print('Original tensor:')\n",
    "print(x0)\n",
    "print('shape:', x0.shape)\n",
    "\n",
    "x1 = x0.view(-1)  # Equivalent to x1 = x0.flatten()\n",
    "print('\\nFlattened tensor:')\n",
    "print(x1)\n",
    "print('shape:', x1.shape)\n",
    "\n",
    "x2 = x1.reshape(-1, 1)\n",
    "print('\\nColumn vector:')\n",
    "print(x2)\n",
    "print('shape:', x2.shape)\n",
    "\n",
    "x3 = x1.view(2, 2, 2)\n",
    "print('\\nRank 3 tensor:')\n",
    "print(x3)\n",
    "print('shape:', x3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e968e105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is b contiguous? False\n",
      "\n",
      "Original tensor b:\n",
      "tensor([[ 0,  4,  8],\n",
      "        [ 1,  5,  9],\n",
      "        [ 2,  6, 10],\n",
      "        [ 3,  7, 11]])\n",
      "\n",
      "view() Failed: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
      "\n",
      "reshape() Succeeded:\n",
      "tensor([[ 0,  4,  8,  1,  5,  9],\n",
      "        [ 2,  6, 10,  3,  7, 11]])\n",
      "\n",
      "Is d contiguous? True\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(12).reshape(3, 4)\n",
    "b = a.t() # .t() makes the tensor non-contiguous\n",
    "print(\"Is b contiguous?\", b.is_contiguous())\n",
    "print(\"\\nOriginal tensor b:\")\n",
    "print(b)\n",
    "\n",
    "try:\n",
    "    c = b.view(2, 6)\n",
    "except Exception as e:\n",
    "    print(\"\\nview() Failed:\", e)\n",
    "\n",
    "d = b.reshape(2, 6)\n",
    "print(\"\\nreshape() Succeeded:\")\n",
    "print(d)\n",
    "print(\"\\nIs d contiguous?\", d.is_contiguous())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b190a85",
   "metadata": {},
   "source": [
    "#### 改变维度顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c588a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[[ 1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8],\n",
      "         [ 9, 10, 11, 12]],\n",
      "\n",
      "        [[13, 14, 15, 16],\n",
      "         [17, 18, 19, 20],\n",
      "         [21, 22, 23, 24]]])\n",
      "shape: torch.Size([2, 3, 4])\n",
      "\n",
      "Swap axes 0 and 1:\n",
      "tensor([[[ 1,  2,  3,  4],\n",
      "         [13, 14, 15, 16]],\n",
      "\n",
      "        [[ 5,  6,  7,  8],\n",
      "         [17, 18, 19, 20]],\n",
      "\n",
      "        [[ 9, 10, 11, 12],\n",
      "         [21, 22, 23, 24]]])\n",
      "torch.Size([3, 2, 4])\n",
      "\n",
      "Permute axes\n",
      "tensor([[[ 1, 13],\n",
      "         [ 2, 14],\n",
      "         [ 3, 15],\n",
      "         [ 4, 16]],\n",
      "\n",
      "        [[ 5, 17],\n",
      "         [ 6, 18],\n",
      "         [ 7, 19],\n",
      "         [ 8, 20]],\n",
      "\n",
      "        [[ 9, 21],\n",
      "         [10, 22],\n",
      "         [11, 23],\n",
      "         [12, 24]]])\n",
      "shape: torch.Size([3, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "x0 = torch.arange(1, 25).reshape(2, 3, 4)\n",
    "print('Original tensor:')\n",
    "print(x0)\n",
    "print('shape:', x0.shape)\n",
    "\n",
    "x1 = x0.transpose(0, 1)\n",
    "print('\\nSwap axes 0 and 1:')\n",
    "print(x1)\n",
    "print(x1.shape)\n",
    "\n",
    "x2 = x0.permute(1, 2, 0)\n",
    "print('\\nPermute axes')\n",
    "print(x2)\n",
    "print('shape:', x2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c527c102",
   "metadata": {},
   "source": [
    "## 计算操作\n",
    "\n",
    "### 归约操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1069d58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[[ 0,  1],\n",
      "         [ 2,  3],\n",
      "         [ 4,  5]],\n",
      "\n",
      "        [[ 6,  7],\n",
      "         [ 8,  9],\n",
      "         [10, 11]]]) torch.Size([2, 3, 2])\n",
      "\n",
      "Sum over entire tensor:\n",
      "tensor(66) torch.Size([])\n",
      "\n",
      "Sum over the first dimension:\n",
      "tensor([[ 6,  8],\n",
      "        [10, 12],\n",
      "        [14, 16]]) torch.Size([3, 2])\n",
      "\n",
      "Sum over the second dimension:\n",
      "tensor([[ 6,  9],\n",
      "        [24, 27]]) torch.Size([2, 2])\n",
      "\n",
      "Sum over the last dimension:\n",
      "tensor([[ 1,  5,  9],\n",
      "        [13, 17, 21]]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(12).reshape(2, 3, 2)\n",
    "print(\"Original tensor:\")\n",
    "print(a, a.shape)\n",
    "\n",
    "print('\\nSum over entire tensor:')\n",
    "print(a.sum(), a.sum().shape)\n",
    "\n",
    "print('\\nSum over the first dimension:')\n",
    "print(a.sum(dim=0), a.sum(dim=0).shape)\n",
    "\n",
    "print('\\nSum over the second dimension:')\n",
    "print(a.sum(dim=1), a.sum(dim=1).shape)\n",
    "\n",
    "print('\\nSum over the last dimension:')\n",
    "print(a.sum(dim=-1), a.sum(dim=-1).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c063ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4co_cny",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
